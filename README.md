# MSC Notes - Shard Router

Um proxy router baseado em hash consistente para distribui√ß√£o de requisi√ß√µes entre shards, desenvolvido como parte das POCs do mestrado em arquitetura celular.

## Vis√£o Geral

O **MSC Shard Router** √© um componente essencial em arquiteturas distribu√≠das que implementa os conceitos de:

- **Sharding**: Particionamento horizontal de dados/servi√ßos
- **Hash Consistente**: Distribui√ß√£o uniforme e est√°vel de chaves entre shards
- **Proxy/Load Balancer**: Roteamento transparente e metrific√°vel de requisi√ß√µes
- **Bulkheads**: Isolamento entre componentes atrav√©s de shards independentes
- **Resili√™ncia**: Toler√¢ncia a falhas atrav√©s de distribui√ß√£o de carga consistente e isolamento

## Arquitetura

O projeto implementa um padr√£o de proxy reverso que utiliza hash consistente para determinar o shard de destino baseado em um header HTTP espec√≠fico:

```
Cliente ‚Üí Shard Router ‚Üí [Hash Consistente] ‚Üí Shard N
```

### Arquitetura Detalhada

```mermaid
graph TB
    subgraph "Cliente"
        C1[Aplica√ß√£o Cliente]
        C2[Header: id_client]
    end
    
    subgraph "Shard Router"
        SR1[HTTP Server :8080]
        SR2[Extrator de Header]
        SR3[Hash Ring Engine]
        SR4[Proxy Reverso]
        SR5[M√©tricas Prometheus]
        
        SR1 --> SR2
        SR2 --> SR3
        SR3 --> SR4
        SR4 --> SR5
    end
    
    subgraph "Shards Backend"
        S1[Shard 01<br/>:8081]
        S2[Shard 02<br/>:8082]
        S3[Shard 03<br/>:8083]
        SN[Shard N<br/>:808N]
    end
    
    subgraph "Observabilidade"
        M1[/metrics endpoint]
        M2[/healthz endpoint]
        M3[Logs estruturados]
    end
    
    C1 --> SR1
    C2 --> SR2
    
    SR4 --> S1
    SR4 --> S2
    SR4 --> S3
    SR4 --> SN
    
    SR5 --> M1
    SR1 --> M2
    SR1 --> M3
    
    style SR3 fill:#e1f5fe
    style C2 fill:#fff3e0
    style S1 fill:#f3e5f5
    style S2 fill:#f3e5f5
    style S3 fill:#f3e5f5
    style SN fill:#f3e5f5
```

## üîß Configura√ß√£o

### Vari√°veis de Ambiente

| Vari√°vel | Descri√ß√£o | Exemplo |
|----------|-----------|---------|
| `ROUTER_PORT` | Porta do servidor router | `8080` |
| `SHARDING_KEY` | Nome do header HTTP usado para sharding | `id_client` |
| `SHARD_01_URL` | URL do primeiro shard | `http://shard01:80` |
| `SHARD_02_URL` | URL do segundo shard | `http://shard02:80` |
| `SHARD_N_URL` | URLs adicionais seguindo o padr√£o | `http://shardN:80` |


### Descoberta Din√¢mica de Shards

O sistema automaticamente descobre shards atrav√©s de regex pattern matching das vari√°veis de ambiente que seguem o padr√£o `SHARD_(\d+)_URL`.

## üöÄ Execu√ß√£o Local

### Docker Compose (Recomendado)

```bash
docker-compose up -d
```

### Build Manual

```bash
# Build da aplica√ß√£o
go mod tidy
go build -o main .

# Configura√ß√£o das vari√°veis
export ROUTER_PORT=8080
export SHARDING_KEY=id_client
export SHARD_01_URL=http://localhost:8081
export SHARD_02_URL=http://localhost:8082
export SHARD_03_URL=http://localhost:8083

# Execu√ß√£o
./main
```

## Algoritmo de Hash Consistente

### Implementa√ß√£o

O sistema utiliza **SHA-512** para gera√ß√£o de hashes, convertidos para `uint64` para posicionamento no anel. Caracter√≠sticas:

- **R√©plicas Virtuais**: Cada shard f√≠sico possui m√∫ltiplas r√©plicas virtuais no anel
- **Distribui√ß√£o Uniforme**: Minimiza hotspots atrav√©s de m√∫ltiplos pontos no anel
- **Busca Bin√°ria**: Localiza√ß√£o eficiente O(log n) do shard de destino

### Fluxo de Roteamento

1. **Extra√ß√£o**: Captura do valor do header definido em `SHARDING_KEY`
2. **Hashing**: C√°lculo SHA-512 do valor + convers√£o para uint64
3. **Lookup**: Busca bin√°ria no anel ordenado pelo hash
4. **Roteamento**: Proxy da requisi√ß√£o para o shard selecionado

### Diagrama do Hash Consistente

```mermaid
graph TD
    A[Requisi√ß√£o HTTP] --> B{Header SHARDING_KEY existe?}
    B -->|N√£o| C[Erro: Header obrigat√≥rio]
    B -->|Sim| D[Extrair valor do header]
    
    D --> E[Hash SHA-512 do valor]
    E --> F[Converter para uint64]
    F --> G[Busca bin√°ria no anel hash]
    
    G --> H{Posi√ß√£o encontrada?}
    H -->|N√£o encontrada| I[Retorna primeiro n√≥ do anel]
    H -->|Encontrada| J[Retorna n√≥ na posi√ß√£o]
    
    I --> K[Proxy para shard selecionado]
    J --> K
    
    K --> L[Registrar m√©tricas]
    L --> M[Retornar resposta]

    subgraph "Estrutura do Hash Ring"
        N[Shard A] --> N1[Replica A-0: hash_A0]
        N --> N2[Replica A-1: hash_A1]
        N --> N3[Replica A-2: hash_A2]
        
        O[Shard B] --> O1[Replica B-0: hash_B0]
        O --> O2[Replica B-1: hash_B1]
        O --> O3[Replica B-2: hash_B2]
        
        P[Shard C] --> P1[Replica C-0: hash_C0]
        P --> P2[Replica C-1: hash_C1]
        P --> P3[Replica C-2: hash_C2]
    end

    subgraph "Anel Hash Ordenado"
        Q[hash_A0] --> R[hash_B1]
        R --> S[hash_C0]
        S --> T[hash_A1]
        T --> U[hash_B2]
        U --> V[hash_C1]
        V --> W[hash_A2]
        W --> X[hash_B0]
        X --> Y[hash_C2]
        Y --> Q
    end
```

### Algoritmo de Distribui√ß√£o

O hash consistente implementado segue os seguintes princ√≠pios:

1. **M√∫ltiplas R√©plicas Virtuais**: Cada shard f√≠sico √© representado por m√∫ltiplas posi√ß√µes no anel hash
2. **Distribui√ß√£o Uniforme**: As r√©plicas virtuais minimizam hotspots e garantem distribui√ß√£o equilibrada
3. **Estabilidade**: Adi√ß√£o/remo√ß√£o de shards afeta apenas os n√≥s adjacentes no anel
4. **Efici√™ncia**: Busca bin√°ria O(log n) para localiza√ß√£o do shard de destino

```mermaid
flowchart LR
    subgraph "Processo de Inicializa√ß√£o"
        A1[Descobrir Shards via ENV] --> A2[Criar Hash Ring]
        A2 --> A3[Para cada Shard]
        A3 --> A4[Gerar N r√©plicas virtuais]
        A4 --> A5[Calcular hash SHA-512]
        A5 --> A6[Adicionar ao anel ordenado]
        A6 --> A3
    end
    
    subgraph "Processo de Roteamento"
        B1[Request com header] --> B2[Extrair chave de sharding]
        B2 --> B3[Hash SHA-512 da chave]
        B3 --> B4[Busca bin√°ria no anel]
        B4 --> B5[Encontrar pr√≥ximo n√≥ >= hash]
        B5 --> B6[Retornar shard f√≠sico]
        B6 --> B7[Proxy da requisi√ß√£o]
    end
```

## Endpoints

### Proxy Principal
- **Endpoint**: `/*` - Aceitando qualquer path ou m√©todo, todos os componentes do request ser√£o repassados para o shard
- **M√©todo**: Todos os m√©todos HTTP
- **Funcionalidade**: Roteamento baseado em hash consistente

### Health Check
- **Endpoint**: `/healthz`
- **M√©todo**: GET
- **Resposta**: Status 200 OK

### M√©tricas Prometheus
- **Endpoint**: `/metrics`
- **M√©todo**: GET
- **M√©tricas Dispon√≠veis**:
  - `shard_router_requests_total`: Contador de requisi√ß√µes por shard
  - `shard_router_responses_total`: Contador de respostas por shard e status

## Monitoramento

### M√©tricas Prometheus

```prometheus
# Requisi√ß√µes totais por shard
shard_router_requests_total{shard="http://shard01:80"}

# Respostas por shard e c√≥digo de status
shard_router_responses_total{shard="http://shard01:80",status="200"}
```

### Logs Estruturados

O sistema produz logs estruturados incluindo:
- Mapeamento de shards durante inicializa√ß√£o
- Roteamento de chaves para hosts espec√≠ficos
- Status de sa√∫de do servidor

## Exemplo de Uso

```bash
# Requisi√ß√£o com header de sharding
curl -H "id_client: user123" http://localhost:9090/

# A requisi√ß√£o ser√° sempre roteada para o mesmo shard baseado no hash de "user123"
```

## Conceitos Acad√™micos Implementados

### Arquitetura Celular
- **Isolamento**: Cada shard opera independentemente
- **Escalabilidade**: Adi√ß√£o din√¢mica de novos shards
- **Toler√¢ncia a Falhas**: Falha de um shard n√£o afeta outros

### Bulkheads Pattern
- **Compartimentaliza√ß√£o**: Recursos isolados por shard
- **Conten√ß√£o de Falhas**: Problemas localizados n√£o se propagam

### Consistent Hashing
- **Estabilidade**: Mudan√ßas m√≠nimas na distribui√ß√£o ao adicionar/remover shards
- **Performance**: Lookup O(log n) com distribui√ß√£o uniforme

## Stack Utilizada

- **Go 1.23**: Runtime e linguagem
- **Gorilla Mux**: Roteamento HTTP
- **Prometheus**: M√©tricas e observabilidade
- **Docker**: Containeriza√ß√£o
- **Air**: Hot reload para desenvolvimento

## Refer√™ncias Acad√™micas

- [Consistent Hashing and Random Trees](https://www.akamai.com/us/en/multimedia/documents/technical-publication/consistent-hashing-and-random-trees-distributed-caching-protocols-for-relieving-hot-spots-on-the-world-wide-web-technical-publication.pdf)
- [Building Microservices - Sam Newman](https://samnewman.io/books/building_microservices/)
- [Site Reliability Engineering - Google](https://sre.google/books/)

## Contribui√ß√£o

Este projeto faz parte de uma pesquisa acad√™mica de mestrado sobre arquitetura celular. Contribui√ß√µes e discuss√µes sobre os conceitos implementados s√£o bem-vindas.